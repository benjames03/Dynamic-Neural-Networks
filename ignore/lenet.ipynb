{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Compose, Normalize, Resize\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Convert to tensors and normalize\n",
    "transform = Compose([\n",
    "    Resize((32, 32)),\n",
    "    ToTensor(),\n",
    "    Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Download training data from open datasets.\n",
    "training_data = datasets.CIFAR10(\n",
    "    root=\"datasets/cifar10\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform,\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.CIFAR10(\n",
    "    root=\"datasets/cifar10\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and testing functions\n",
    "def train(dataloader, model, loss_function, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(\"cpu\"), y.to(\"cpu\")\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_function(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "def test(dataloader, model, loss_function):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(\"cpu\"), y.to(\"cpu\")\n",
    "            pred = model(X)\n",
    "            test_loss += loss_function(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    return correct, test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Conv2d(3, 30, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(30, 13, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Flatten(start_dim=1, end_dim=-1)\n",
      "    (7): Linear(in_features=208, out_features=120, bias=True)\n",
      "    (8): ReLU()\n",
      "    (9): Linear(in_features=120, out_features=86, bias=True)\n",
      "    (10): ReLU()\n",
      "    (11): Linear(in_features=86, out_features=10, bias=True)\n",
      "    (12): Softmax(dim=1)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=30, kernel_size=3, stride=1, padding=0), \n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(in_channels=30, out_channels=13, kernel_size=3, stride=1, padding=0), \n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=3),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(208, 120),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(120, 86),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(86, 10),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(\"cpu\")\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------\n",
      "Epoch 1\n",
      "Accuracy: 41.1%, Avg loss: 2.047176\n",
      "-------------------------------\n",
      "Epoch 2\n",
      "Accuracy: 45.4%, Avg loss: 2.003630\n",
      "-------------------------------\n",
      "Epoch 3\n",
      "Accuracy: 49.0%, Avg loss: 1.966004\n",
      "-------------------------------\n",
      "Epoch 4\n",
      "Accuracy: 48.6%, Avg loss: 1.971656\n",
      "-------------------------------\n",
      "Epoch 5\n",
      "Accuracy: 55.0%, Avg loss: 1.909602\n",
      "-------------------------------\n",
      "Epoch 6\n",
      "Accuracy: 58.4%, Avg loss: 1.876141\n",
      "-------------------------------\n",
      "Epoch 7\n",
      "Accuracy: 57.3%, Avg loss: 1.886723\n",
      "-------------------------------\n",
      "Epoch 8\n",
      "Accuracy: 61.6%, Avg loss: 1.841258\n",
      "-------------------------------\n",
      "Epoch 9\n",
      "Accuracy: 59.0%, Avg loss: 1.867739\n",
      "-------------------------------\n",
      "Epoch 10\n",
      "Accuracy: 61.1%, Avg loss: 1.846611\n"
     ]
    }
   ],
   "source": [
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 15\n",
    "acc, loss = [], []\n",
    "for t in range(epochs):\n",
    "    print(f\"-------------------------------\\nEpoch {t+1}\")\n",
    "    train(train_dataloader, model, loss_function, optimizer)\n",
    "    temp_acc, temp_loss = test(test_dataloader, model, loss_function)\n",
    "    acc.append(temp_acc)\n",
    "    loss.append(temp_loss)\n",
    "    print(f\"Accuracy: {(100*acc[-1]):>0.1f}%, Avg loss: {loss[-1]:>8f}\")\n",
    "\n",
    "\n",
    "# # with open(\"results/results.txt\", \"a\") as file:\n",
    "# #     file.write(f\"Accuracy: {(100*acc[-1]):>0.1f}%, Avg loss: {loss[-1]:>8f}, Epochs: {epochs}\\n{model}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m fig, (ax1, ax2) \u001b[38;5;241m=\u001b[39m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m4\u001b[39m))\n\u001b[1;32m      3\u001b[0m ax1\u001b[38;5;241m.\u001b[39mplot(np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m1\u001b[39m, epochs\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m), acc, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblue\u001b[39m\u001b[38;5;124m\"\u001b[39m, marker\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mo\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m ax1\u001b[38;5;241m.\u001b[39mset_title(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy over epochs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "ax1.plot(np.arange(1, epochs+1), acc, color=\"blue\", marker=\"o\")\n",
    "ax1.set_title(\"Accuracy over epochs\")\n",
    "ax1.set_xlabel(\"Epochs\")\n",
    "ax1.set_ylabel(\"Accuracy\")\n",
    "\n",
    "ax2.plot(np.arange(1, epochs+1), loss, color=\"red\", marker=\"o\")\n",
    "ax2.set_title(\"Loss over epochs\")\n",
    "ax2.set_xlabel(\"Epochs\")\n",
    "ax2.set_ylabel(\"Loss\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Saving the model\n",
    "# model_name = \"test_model3\"\n",
    "# torch.save(model.state_dict(), f\"models/{model_name}.pth\")\n",
    "# print(f\"Saved PyTorch Model State to models/{model_name}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the model FAIL\n",
    "# model_name = \"test_model2\"\n",
    "# loaded_model = NeuralNetwork().to(\"cpu\")\n",
    "# loaded_model.load_state_dict(torch.load(f\"models/{model_name}.pth\", weights_only=True))\n",
    "# print(\"Loaded!\\n\", loaded_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
